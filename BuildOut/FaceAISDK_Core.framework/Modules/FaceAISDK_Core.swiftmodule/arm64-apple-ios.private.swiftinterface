// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.9.2 (swiftlang-5.9.2.2.56 clang-1500.1.0.2.5)
// swift-module-flags: -target arm64-apple-ios16.6 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name FaceAISDK_Core
// swift-module-flags-ignorable: -enable-bare-slash-regex
import AVFoundation
import Combine
import CoreVideo
import Foundation
import MLImage
import MLKitCommon
import MLKitFaceDetection
import MLKitVision
import Swift
import SwiftUI
import TensorFlowLite
import UIKit
import Vision
import VisionKit
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
@objc @_inheritsConvenienceInitializers public class VerifyFaceCore : ObjectiveC.NSObject, Foundation.ObservableObject, AVFoundation.AVCaptureVideoDataOutputSampleBufferDelegate {
  @Combine.Published @_projectedValueProperty($verifyFaceTips) public var verifyFaceTips: Swift.String {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $verifyFaceTips: Combine.Published<Swift.String>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  @Combine.Published @_projectedValueProperty($verifyFaceTipsExtra) public var verifyFaceTipsExtra: Swift.String {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $verifyFaceTipsExtra: Combine.Published<Swift.String>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  @Combine.Published @_projectedValueProperty($similarity) public var similarity: Swift.Float {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $similarity: Combine.Published<Swift.Float>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  final public let captureSession: AVFoundation.AVCaptureSession
  public func stopSession()
  public func initFaceAISDK(faceIDParam: Swift.String)
  @objc override dynamic public init()
  @objc public func captureOutput(_ output: AVFoundation.AVCaptureOutput, didOutput sampleBuffer: CoreMedia.CMSampleBuffer, from connection: AVFoundation.AVCaptureConnection)
  public func setFaceID(faceIDValue: Swift.String)
  public typealias ObjectWillChangePublisher = Combine.ObservableObjectPublisher
  @objc deinit
}
public struct CameraPreview : SwiftUI.UIViewControllerRepresentable {
  public init(session: AVFoundation.AVCaptureSession, cameraSize: CoreFoundation.CGFloat)
  @_Concurrency.MainActor(unsafe) public func makeUIViewController(context: FaceAISDK_Core.CameraPreview.Context) -> UIKit.UIViewController
  @_Concurrency.MainActor(unsafe) public func updateUIViewController(_ uiViewController: UIKit.UIViewController, context: FaceAISDK_Core.CameraPreview.Context)
  public typealias Body = Swift.Never
  public typealias Coordinator = Swift.Void
  public typealias UIViewControllerType = UIKit.UIViewController
}
@_hasMissingDesignatedInitializers final public class FaceAIUtils {
  public static func cosineSimilarity(_ a: [Swift.Float], _ b: [Swift.Float]) -> Swift.Float
  public static func getEmbedding(from faceImage: UIKit.UIImage, using interpreter: TensorFlowLite.Interpreter?) -> [Swift.Float]?
  public static func getEmbeddings2(from image1: UIKit.UIImage, and image2: UIKit.UIImage, using interpreter: TensorFlowLite.Interpreter?) -> ([Swift.Float], [Swift.Float])?
  public static func loadImageFromDocuments(fileName: Swift.String) -> UIKit.UIImage?
  #if compiler(>=5.3) && $AsyncAwait
  public static func faceAlign(image: UIKit.UIImage, landmarks: [CoreFoundation.CGPoint]) async -> UIKit.UIImage
  #endif
  #if compiler(>=5.3) && $AsyncAwait
  public static func getFaceLandmarks(from image: UIKit.UIImage) async -> [CoreFoundation.CGPoint]?
  #endif
  @objc deinit
}
@_hasMissingDesignatedInitializers final public class TFLiteManager {
  public static func loadModel(name: Swift.String) -> Foundation.Data?
  public static func loadModelFromSubBundle(subBundleName: Swift.String, modelName: Swift.String) -> Foundation.Data?
  public static func loadModelPathFromSubBundle(subBundleName: Swift.String, modelName: Swift.String) -> Swift.String?
  @objc deinit
}
@_hasMissingDesignatedInitializers public class UIUtilities {
  public static func imageOrientation(fromDevicePosition devicePosition: AVFoundation.AVCaptureDevice.Position = .front) -> UIKit.UIImage.Orientation
  public static func sampleBufferToImage(from sampleBuffer: CoreMedia.CMSampleBuffer, orientation: UIKit.UIImage.Orientation) -> UIKit.UIImage?
  @objc deinit
}
@objc @_inheritsConvenienceInitializers public class AddFaceCore : ObjectiveC.NSObject, Foundation.ObservableObject, AVFoundation.AVCaptureVideoDataOutputSampleBufferDelegate {
  @Combine.Published @_projectedValueProperty($canAddFace) public var canAddFace: UIKit.UIImage {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $canAddFace: Combine.Published<UIKit.UIImage>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  @Combine.Published @_projectedValueProperty($addFaceTips) public var addFaceTips: Swift.String {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $addFaceTips: Combine.Published<Swift.String>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  @Combine.Published @_projectedValueProperty($addFaceTipsExtra) public var addFaceTipsExtra: Swift.String {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $addFaceTipsExtra: Combine.Published<Swift.String>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  @Combine.Published @_projectedValueProperty($readyConfirmFace) public var readyConfirmFace: Swift.Bool {
    get
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    set
    @available(iOS 13.0, tvOS 13.0, watchOS 6.0, macOS 10.15, *)
    _modify
  }
  public var $readyConfirmFace: Combine.Published<Swift.Bool>.Publisher {
    get
    @available(iOS 14.0, tvOS 14.0, watchOS 7.0, macOS 11.0, *)
    set
  }
  final public let captureSession: AVFoundation.AVCaptureSession
  public var isDisposing: Swift.Bool
  public func stopSession()
  public func setUpCaptureSession()
  @objc public func captureOutput(_ output: AVFoundation.AVCaptureOutput, didOutput sampleBuffer: CoreMedia.CMSampleBuffer, from connection: AVFoundation.AVCaptureConnection)
  public func reInit()
  @objc override dynamic public init()
  public func goSaveFace(fileName: Swift.String)
  public typealias ObjectWillChangePublisher = Combine.ObservableObjectPublisher
  @objc deinit
}
